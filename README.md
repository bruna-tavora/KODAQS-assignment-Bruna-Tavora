This repository was created for the Kodaqs course as part of the KDQ_CP2_4_Module_4.1 assignment on data quality. It includes Python code for data analysis that I developed with the assistance of DeepSeek AI.

After conducting tests comparing the free version of ChatGPT and DeepSeek, I achieved better results when running the code generated by DeepSeek. I prompted the generative AI with instructions such as: “Generate Python code to perform topic modeling” and “Use common libraries and transformers such as pandas and BERTopic.” I used Colab to run the Python code. 

I then used this code both to obtain an overview of my dataset and to practice different coding strategies. My dataset consists of digital behavioral data extracted using a social listening tool called Fanpage Karma. The data covers 10 years (2015-2025) of digital communication from the Parliamentary Agriculture Front’s Meta platforms (including Instagram, Facebook, and the Meta Ads Library). This is a political coalition in Brazil embedded in neo-extractivist public policies and practices.


##### Network Analysis 

This script implements a keyword co-occurrence network analysis pipeline using Python. The objective is to transform a structured textual dataset (comma-separated keywords) into a weighted undirected graph representing term associations across documents.

##Data Input: The script reads a CSV file using pandas, assuming the presence of a “keywords” column containing comma-separated terms for each observation. Each row is treated as an independent document (or unit of analysis).

##Preprocessing: The preprocessing stage includes converting all keywords to lowercase, trimming leading and trailing whitespace, normalizing internal spacing using regular expressions, and removing duplicate keywords within the same document using set(). This ensures consistent token representation and prevents intra-document duplication from artificially inflating edge weights.

Co-occurrence Extraction

For each document, the script generates all unordered keyword pairs using itertools.combinations applied to the cleaned keyword list. Each pair represents a co-occurrence relationship. The collections.Counter object aggregates these pairs across the dataset, producing frequency counts that define edge weights in the network.

Graph Construction

A weighted undirected graph is created using NetworkX. Nodes represent unique keywords, and edges represent keyword pairs that co-occur at least once. Edge weights correspond to the frequency of co-occurrence across documents. In some visualizations, filtering is applied (e.g., selecting the Top 20, Top 40, or Top 50 most frequent pairs) to reduce network density and improve interpretability.

Visualization Strategy

The graph is visualized using matplotlib with a force-directed layout (spring_layout). Node size is scaled according to node degree (number of connections), and edge width is proportional to co-occurrence weight. Some versions include manual highlighting of specific keywords to emphasize their structural position. A fixed random seed is used to ensure layout reproducibility.

Analytical Purpose

The resulting network structure allows for the identification of high-degree nodes (central terms), detection of strongly associated keyword clusters, inspection of thematic concentration patterns, and support for subsequent qualitative or discourse-based analysis. The implementation prioritizes exploratory structural analysis and visualization clarity rather than advanced network metrics such as modularity, centrality measures, or community detection, which can be incorporated as future extensions.
