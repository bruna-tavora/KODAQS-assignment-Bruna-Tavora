This repository was created for the Kodaqs course as part of the KDQ_CP2_4_Module_4.1 assignment on data quality. It includes Python code for data analysis that I developed with the assistance of DeepSeek AI.

After conducting tests comparing the free version of ChatGPT and DeepSeek, I achieved better results when running the code generated by DeepSeek. I prompted the generative AI with the following instruction: "Generate code that allows me to perform network analysis using keywords as the unit of analysis, with Python as the main programming language and Google Colab as the development environment."

I then used this code both to obtain an overview of my dataset and to practice different coding strategies. My dataset consists of digital behavioral data extracted using the web application YouTube Data Tools, which was employed to collect all videos published on the coalition’s YouTube channel. The downloaded CSV file includes a column containing keywords assigned by the channel’s users. YTDT is part of the Digital Methods Initiative, UvA (https://ytdt.digitalmethods.net/faq.php)

The Parliamentary Agriculture Front (Frente Parlamentar da Agropecuária – FPA) is a cross-party congressional coalition in Brazil composed of legislators who represent agribusiness interests. It plays a significant role in shaping agricultural, environmental, and land-use policies, and it is closely associated with neo-extractivist development strategies focused on commodity production and export-oriented growth. The coalition also influences Brazil’s position in international trade negotiations related to agriculture and natural resources.


##### Network Analysis 

This script implements a keyword co-occurrence network analysis pipeline using Python. The objective is to transform a structured textual dataset (comma-separated keywords) into a weighted undirected graph representing term associations across documents.

##Data Input: The script reads a CSV file using pandas, assuming the presence of a “keywords” column containing comma-separated terms for each observation. Each row is treated as an independent document (or unit of analysis).

##Preprocessing: The preprocessing stage includes converting all keywords to lowercase, trimming leading and trailing whitespace, normalizing internal spacing using regular expressions, and removing duplicate keywords within the same document using set(). This ensures consistent token representation and prevents intra-document duplication from artificially inflating edge weights.

##Co-occurrence Extraction: For each document, the script generates all unordered keyword pairs using itertools.combinations applied to the cleaned keyword list. Each pair represents a co-occurrence relationship. The collections.Counter object aggregates these pairs across the dataset, producing frequency counts that define edge weights in the network.

##Graph Construction: A weighted undirected graph is created using NetworkX. Nodes represent unique keywords, and edges represent keyword pairs that co-occur at least once. Edge weights correspond to the frequency of co-occurrence across documents. In some visualizations, filtering is applied (e.g., selecting the Top 20, Top 40, or Top 50 most frequent pairs) to reduce network density and improve interpretability.

##Visualization Strategy: The graph is visualized using matplotlib with a force-directed layout (spring_layout). Node size is scaled according to node degree (number of connections), and edge width is proportional to co-occurrence weight. Some versions include manual highlighting of specific keywords to emphasize their structural position. 

##Analytical Purpose: The resulting network structure allows for the identification of high-degree nodes (central terms), detection of strongly associated keyword clusters, inspection of thematic concentration patterns, and support for subsequent qualitative or discourse-based analysis. 

The implementation prioritizes exploratory structural analysis and visualization clarity and is limited in terms of advanced network metrics such as modularity, centrality measures, or community detection, which can be incorporated as future extensions.
